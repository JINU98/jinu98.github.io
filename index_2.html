<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>Jinendra Malekar - Resume</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.5;
            margin: 40px;
            background-color: #fff;
            color: #000;
        }
        h1, h2 {
            color: #003366;
            margin-bottom: 5px;
        }
        h1 {
            font-size: 28px;
            border-bottom: 2px solid #003366;
            padding-bottom: 5px;
        }
        p, li {
            font-size: 14px;
        }
        ul {
            padding-left: 20px;
        }
        .section {
            margin-bottom: 20px;
        }
        .contact a {
            color: #003366;
            text-decoration: none;
        }
    </style>
</head>
<body>

    <h1>Jinendra Malekar</h1>
    <p><strong>PhD Student, ICAS Lab</strong> <br>
    University of South Carolina <br>
    Email: <a href="mailto:jmalekar@email.sc.edu">jmalekar@email.sc.edu</a> | 
    GitHub: <a href="https://github.com/JINU98" target="_blank">github.com/JINU98</a> | 
    LinkedIn: <a href="https://www.linkedin.com/in/jinendramalekar/" target="_blank">linkedin.com/in/jinendramalekar</a>
    </p>

    <div class="section">
        <h2>Research Interests</h2>
        <p>Optimizing Large Language Models (LLMs) for deployment on resource-constrained edge devices; quantization; hardware acceleration; efficient AI systems; 1-bit LLM architectures.</p>
    </div>

    <div class="section">
        <h2>Education</h2>
        <p><strong>PhD in Computer Engineering</strong> <br>
        University of South Carolina <br>
        ICAS Lab, Advisor: Prof. Ramtin Zand <br>
        Ongoing</p>
    </div>

    <div class="section">
        <h2>Publications</h2>
        <ul>
            <li>
                <strong>
                    <a href="https://arxiv.org/abs/2504.02118" target="_blank">
                        LLMPi: Optimizing LLMs for High-Throughput on Raspberry Pi
                    </a>
                </strong> <br>
                M. Ardakani, J. Malekar, R. Zand <br>
                arXiv preprint arXiv:2504.02118, 2025
            </li>
            <li>
                <strong>
                    <a href="https://arxiv.org/abs/2504.01994" target="_blank">
                        PIM-LLM: A High-Throughput Hybrid PIM Architecture for 1-bit LLMs
                    </a>
                </strong> <br>
                J. Malekar, P. Chandarana, M.H. Amin, M.E. Elbtity, R. Zand <br>
                arXiv preprint arXiv:2504.01994, 2025
            </li>
            <li>
                <strong>
                    <a href="https://arxiv.org/abs/2408.11939" target="_blank">
                        Matmul or No Matmul in the Era of 1-bit LLMs
                    </a>
                </strong> <br>
                J. Malekar, M.E. Elbtity, R. Zand <br>
                arXiv preprint arXiv:2408.11939, 2024
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>Projects</h2>
        <ul>
            <li>Developing highly quantized LLMs for Raspberry Pi and edge devices</li>
            <li>Designing hybrid analog/digital accelerators for ultra-low-power AI inference</li>
            <li>Research on 1-bit LLM architectures and their performance trade-offs</li>
        </ul>
    </div>

</body>
</html>
